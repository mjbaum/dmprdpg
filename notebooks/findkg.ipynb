{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iso-mirror analysis on the FinDKG data\n",
    "\n",
    "First, we import the library `dmprdpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dmprdpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "## Compile with tikz and times font\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import the FinDKG data and related mapping files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataframe from the .txt file\n",
    "df = pd.read_csv('../data/FinDKG-full/findkg.txt', sep='\\t', header=None)\n",
    "df.columns = ['Source Entity', 'Relation', 'Target Entity', 'Timestamp', 'Zero']\n",
    "map_entity = pd.read_csv('../data/FinDKG-full/entity2id.txt', sep='\\t', header=None)\n",
    "map_relation = pd.read_csv('../data/FinDKG-full/relation2id.txt', sep='\\t', header=None)\n",
    "map_times = pd.read_csv('../data/FinDKG-full/time2id.txt', sep='\\t', header=None)\n",
    "\n",
    "# Print the number of rows and columns\n",
    "N = len(map_entity)\n",
    "K = len(map_relation)\n",
    "print(\"Number of entities: \", N)\n",
    "print(\"Number of relations: \", K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maximum timestamp\n",
    "T = max(df['Timestamp'])\n",
    "## Group weeks by quarter: 1-13 -> 1, 14-26 -> 2, 27-39 -> 3, 40-52 -> 4 (52 weeks in a year)\n",
    "df['Year'] = df['Timestamp'] // 52 + 2018\n",
    "df['Quarter'] = (df['Timestamp'] % 52) // 13 + 1\n",
    "## Concatenate df['Year'] and df['Quarter'] to get the quarter of the year in a string\n",
    "df['YearQuarter'] = df['Year'].astype(str) + '-Q' + df['Quarter'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count number of events per YearQuarter\n",
    "print(df.groupby('Timestamp').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.groupby('Timestamp').size())\n",
    "## plt.ylim(0,800)\n",
    "plt.xlabel('Week number')\n",
    "plt.ylabel('Number of events')\n",
    "plt.savefig('figures/FinDKG-full-events.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.groupby('YearQuarter').size())\n",
    "plt.xticks(np.arange(0, len(df.groupby('YearQuarter').size())), df.groupby('YearQuarter').size().index, rotation=45)\n",
    "plt.xlabel('Quarter number')\n",
    "plt.ylabel('Number of events')\n",
    "# plt.ylim(0,8000)\n",
    "plt.savefig('figures/FinDKG-full-events-quarter.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider only a subset of months with a sufficient number of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each 'YearQuarter' occurs\n",
    "count = df['YearQuarter'].value_counts()\n",
    "# Calculate edge density per month\n",
    "subset_times = np.sort(list(count[count > 5000].index))\n",
    "# Filter out the rows with 'YearQuarter' not in subset_times\n",
    "df = df[df['YearQuarter'].isin(subset_times)]\n",
    "# Number of time points\n",
    "T = len(subset_times)\n",
    "## Map 'YearQuarter' to integers based on the alphabetical order\n",
    "map_year_quarter = {yq: i for i, yq in enumerate(sorted(df['YearQuarter'].unique()))}\n",
    "print(\"Number of time points: \", T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all entities observed less than 10 times\n",
    "count = df['Source Entity'].value_counts() + df['Target Entity'].value_counts()\n",
    "entities = count.index ##count[count > 10].index\n",
    "# Filter out the rows with 'Source Entity' and 'Target Entity' not in entities\n",
    "df = df[df['Source Entity'].isin(entities) & df['Target Entity'].isin(entities)]\n",
    "# Number of entities\n",
    "N = len(entities)\n",
    "## Map entities to integers based on the alphabetical order\n",
    "map_entity = {e: i for i, e in enumerate(sorted(entities))}\n",
    "## Use the mapping in the DF\n",
    "df['Source Entity'] = df['Source Entity'].map(map_entity)\n",
    "df['Target Entity'] = df['Target Entity'].map(map_entity)\n",
    "print(\"Number of entities: \", N)\n",
    "print(\"Number of events: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct adjacency matrices for each pair `(Event Type, Month)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create the dictionary to hold the sparse matrices\n",
    "A_dict = {}\n",
    "\n",
    "# Loop over the unique combinations\n",
    "for t, event_quarter_id in enumerate(subset_times):\n",
    "    for event_type_id in range(K):\n",
    "        # Filter the DataFrame for the current combination\n",
    "        filtered_df = df[(df['YearQuarter'] == event_quarter_id) & (df['Relation'] == event_type_id)]\n",
    "        # Create a pivot table\n",
    "        rows = list(filtered_df['Source Entity'])\n",
    "        columns = list(filtered_df['Target Entity'])\n",
    "        values = [1.] * len(filtered_df)\n",
    "        # Convert the pivot table to a sparse matrix\n",
    "        sparse_matrix = csr_matrix((values, (rows, columns)), shape=(N, N))\n",
    "        # Add the sparse matrix to the dictionary\n",
    "        A_dict[(event_type_id, t)] = sparse_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the DUASE from the adjacency matrices, using the function `duase` in `dmprdpg`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = dmprdpg.singular_values_A_tilde(A_dict, K=K, T=T, d_max=100)\n",
    "plt.plot(S, color='blue', marker='o', lw=0.5)\n",
    "plt.xlabel('\\r$d$')\n",
    "plt.ylabel('Singular values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dmprdpg.eigengap(S, x=3)[-1]\n",
    "print(f'Estimated dimension: {d}')\n",
    "X, Y = dmprdpg.duase(A_dict, K=K, T=T, d=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `isomirror` function on the left embedding $\\hat{\\mathbf{X}}^k,\\ k=1,\\dots,K$, and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = dmprdpg.mirror(X, n_components_cmds=2, n_components_isomap=1, verbose=False)\n",
    "V_vals = np.sort(V[:,0])[::-1]\n",
    "V_keys = np.array(map_relation[0][np.argsort(V[:,0])[::-1]])\n",
    "plt.plot(np.arange(K), V_vals, marker='o', color='black', lw=1, markerfacecolor='coral')\n",
    "# Plot in the legend \n",
    "plt.xticks(np.arange(K), labels=V_keys, rotation=90)\n",
    "# Set xlabel and ylabel\n",
    "plt.xlabel('Relation')\n",
    "plt.ylabel('Iso-mirror')\n",
    "## Save as PDF\n",
    "plt.savefig('figures/findkg_isomap_event_types.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for the right embedding $\\hat{\\mathbf{Y}}^t,\\ t=1,\\dots,T$, and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = dmprdpg.mirror(Y, n_components_cmds=2, n_components_isomap=1, verbose=False)\n",
    "plt.plot(np.arange(len(V))+1, V, marker='o', color='black', markerfacecolor='coral', lw=1)\n",
    "plt.xticks(np.arange(len(V))+1, labels=list(map_year_quarter.keys()), rotation=45)\n",
    "# Set xlabel and ylabel\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Iso-mirror')\n",
    "# Add vertical dotted line in Q1 2022 for Russian invasion of Ukraine\n",
    "plt.axvline(x=map_year_quarter['2022-Q1']+1, color='black', linestyle='dotted') \n",
    "# Add text for the vertical line\n",
    "plt.text(map_year_quarter['2022-Q1']+1.45, np.min(V), 'February 2022: Russian invasion of Ukraine', rotation=90, verticalalignment='bottom')\n",
    "## Save as PDF\n",
    "plt.savefig('figures/findkg_isomap_time.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter all entries with relation 1 (Control)\n",
    "df_control = df[df['Relation'] == 1]\n",
    "## Construct A_dict for the control relation\n",
    "A_dict_control = {}\n",
    "for t, event_quarter_id in enumerate(subset_times):\n",
    "    # Filter the DataFrame for the current combination\n",
    "    filtered_df = df_control[df_control['YearQuarter'] == event_quarter_id]\n",
    "    # Create a pivot table\n",
    "    rows = list(filtered_df['Source Entity'])\n",
    "    columns = list(filtered_df['Target Entity'])\n",
    "    values = [1.] * len(filtered_df)\n",
    "    # Convert the pivot table to a sparse matrix\n",
    "    sparse_matrix = csr_matrix((values, (rows, columns)), shape=(N, N))\n",
    "    # Add the sparse matrix to the dictionary\n",
    "    A_dict_control[(0, t)] = sparse_matrix\n",
    "\n",
    "## Repeat the analysis for the control relation to obtain the ISOMIRROR only for that graph\n",
    "X_c, Y_c = dmprdpg.duase(A_dict_control, K=1, T=T, d=d)\n",
    "V_c = dmprdpg.mirror(Y_c, n_components_cmds=2, n_components_isomap=1, verbose=False)\n",
    "plt.plot(np.arange(len(V_c))+1, V_c, marker='o', color='black', markerfacecolor='coral', lw=1)\n",
    "plt.xticks(np.arange(len(V_c))+1, labels=list(map_year_quarter.keys()), rotation=45)\n",
    "# Set xlabel and ylabel\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Iso-mirror')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat the analysis above separately for all relation types\n",
    "V_dict = {}\n",
    "for k in range(K):\n",
    "    # Filter the DataFrame for the current combination\n",
    "    df_relation = df[df['Relation'] == k]\n",
    "    # Construct A_dict for the current relation type\n",
    "    A_dict_k = {}\n",
    "    for t, event_quarter_id in enumerate(subset_times):\n",
    "        # Filter the DataFrame for the current combination\n",
    "        filtered_df = df_relation[df_relation['YearQuarter'] == event_quarter_id]\n",
    "        # Create a pivot table\n",
    "        rows = list(filtered_df['Source Entity'])\n",
    "        columns = list(filtered_df['Target Entity'])\n",
    "        values = [1.] * len(filtered_df)\n",
    "        # Convert the pivot table to a sparse matrix\n",
    "        sparse_matrix = csr_matrix((values, (rows, columns)), shape=(N, N))\n",
    "        # Add the sparse matrix to the dictionary\n",
    "        A_dict_k[(0, t)] = sparse_matrix\n",
    "    # Repeat the analysis for the current relation type to obtain the ISOMIRROR only for that graph with d=9\n",
    "    X_k, Y_k = dmprdpg.duase(A_dict_k, K=1, T=T, d=d)\n",
    "    V_k = dmprdpg.mirror(Y_k, n_components_cmds=2, n_components_isomap=1, verbose=False)\n",
    "    V_dict[k] = V_k\n",
    "\n",
    "## Plot the Iso-mirror for all relation types\n",
    "for k in range(K):\n",
    "    plt.plot(np.arange(len(V_dict[k]))+1, V_dict[k], lw=1, c='lightgrey')\n",
    "    plt.plot(np.arange(len(V_dict[k]))+1, -V_dict[k], lw=1, c='lightgrey')\n",
    "plt.xticks(np.arange(len(V_dict[k]))+1, labels=list(map_year_quarter.keys()), rotation=45)\n",
    "# Set xlabel and ylabel\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Iso-mirror')\n",
    "# Plot the global Iso-mirror on top\n",
    "plt.plot(np.arange(len(V))+1, V, marker='o', color='black', lw=1, markerfacecolor='coral')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the Iso-mirror from the COMBINED adjacency matrix\n",
    "A_dict_combined = {}\n",
    "for t, event_quarter_id in enumerate(subset_times):\n",
    "    # Filter the DataFrame for the current combination\n",
    "    filtered_df = df[df['YearQuarter'] == event_quarter_id]\n",
    "    # Create a pivot table\n",
    "    rows = list(filtered_df['Source Entity'])\n",
    "    columns = list(filtered_df['Target Entity'])\n",
    "    values = [1.] * len(filtered_df)\n",
    "    # Convert the pivot table to a sparse matrix\n",
    "    sparse_matrix = csr_matrix((values, (rows, columns)), shape=(N, N))\n",
    "    # Add the sparse matrix to the dictionary\n",
    "    A_dict_combined[(0, t)] = sparse_matrix\n",
    "\n",
    "X_combined, Y_combined = dmprdpg.duase(A_dict_combined, K=1, T=T, d=d)\n",
    "V_combined = dmprdpg.mirror(Y_combined, n_components_cmds=2, n_components_isomap=1, verbose=False)\n",
    "\n",
    "## Plot the Iso-mirror for all relation types\n",
    "for k in range(K):\n",
    "    if np.mean(np.abs(-V_dict[k] - V)) > np.mean(np.abs(-V_dict[k] + V)):\n",
    "        plt.plot(np.arange(len(V_dict[k]))+1, V_dict[k], lw=1, c='lightgrey')\n",
    "    else:\n",
    "        plt.plot(np.arange(len(V_dict[k]))+1, -V_dict[k], lw=1, c='lightgrey')\n",
    "plt.xticks(np.arange(len(V_dict[k]))+1, labels=list(map_year_quarter.keys()), rotation=45)\n",
    "\n",
    "# Set xlabel and ylabel\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Iso-mirror')\n",
    "# Plot the global Iso-mirror on top\n",
    "plt.plot(np.arange(len(V))+1, V, marker='o', color='black', lw=1, markerfacecolor='coral', label='DUASE')\n",
    "plt.plot(np.arange(len(V_combined))+1, -V_combined, marker='s', color='black', markerfacecolor='blue', lw=1, label='UASE on combined adjacency matrix', ls='dashed')\n",
    "# Plot something empty to make the legend appear\n",
    "plt.plot([], [], lw=1, c='lightgray', label='UASE on layer-specific adjacency matrices')\n",
    "# Add legend\n",
    "plt.legend(frameon=False, loc='upper left')\n",
    "# Add vertical dotted line in Q1 2022 for Russian invasion of Ukraine\n",
    "plt.axvline(x=map_year_quarter['2022-Q1']+1, color='black', linestyle='dotted') \n",
    "# Add text for the vertical line\n",
    "plt.text(map_year_quarter['2022-Q1']+1.45, np.min(V)-0.01, 'February 2022: Russian invasion of Ukraine', rotation=90, verticalalignment='bottom')\n",
    "\n",
    "## Save as PDF\n",
    "plt.savefig('figures/findkg_isomap_time_compared.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat on the left embedding for the combined adjacency matrix\n",
    "## Calculate the Iso-mirror from the COMBINED adjacency matrix\n",
    "A_dict_combined = {}\n",
    "for k in range(K):\n",
    "    # Filter the DataFrame for the current combination\n",
    "    filtered_df = df[df['Relation'] == k]\n",
    "    # Create a pivot table\n",
    "    rows = list(filtered_df['Source Entity'])\n",
    "    columns = list(filtered_df['Target Entity'])\n",
    "    values = [1.] * len(filtered_df)\n",
    "    # Convert the pivot table to a sparse matrix\n",
    "    sparse_matrix = csr_matrix((values, (rows, columns)), shape=(N, N))\n",
    "    # Add the sparse matrix to the dictionary\n",
    "    A_dict_combined[(k, 0)] = sparse_matrix\n",
    "\n",
    "X_combined, Y_combined = dmprdpg.duase(A_dict_combined, K=K, T=1, d=9)\n",
    "V_combined = dmprdpg.mirror(X_combined, n_components_cmds=2, n_components_isomap=1, verbose=False)\n",
    "\n",
    "V = dmprdpg.mirror(X, n_components_cmds=2, n_components_isomap=1, verbose=False)\n",
    "vv = np.argsort(V[:,0])[::-1]\n",
    "V_keys = np.array(map_relation[0][vv])\n",
    "\n",
    "plt.plot(np.arange(K), V[:,0][vv], marker='o', color='black', lw=1, markerfacecolor='coral', label='DUASE')\n",
    "plt.plot(np.arange(K), V_combined[:,0][vv], marker='s', color='black', lw=1, markerfacecolor='blue', ls='dashed', label='UASE on combined adjacency matrix')\n",
    "# Plot in the legend\n",
    "plt.xticks(np.arange(K), labels=V_keys, rotation=90)\n",
    "# Set xlabel and ylabel\n",
    "plt.xlabel('Relation')\n",
    "plt.ylabel('Iso-mirror')\n",
    "## Add legend to the bottom left\n",
    "plt.legend(frameon=False, loc='lower left')\n",
    "## Save as PDF\n",
    "plt.savefig('figures/findkg_isomap_event_types_compared.pdf', bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
